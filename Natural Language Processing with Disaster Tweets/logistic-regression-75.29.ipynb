{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/nlp-getting-started/sample_submission.csv\n/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/nlp-getting-started/train.csv')\ntest_df = pd.read_csv('../input/nlp-getting-started/test.csv')\nprint(train_df.head(5))\nprint(test_df.head(5))","execution_count":2,"outputs":[{"output_type":"stream","text":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  \n   id keyword location                                               text\n0   0     NaN      NaN                 Just happened a terrible car crash\n1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove NA\ntrain_df['keyword'].fillna(\"None\", inplace = True)\ntrain_df['location'].fillna(\"None\", inplace = True)\ntest_df['keyword'].fillna(\"None\", inplace = True)\ntest_df['location'].fillna(\"None\", inplace = True)\nprint(train_df.head(5))\nprint(test_df.head(5))","execution_count":8,"outputs":[{"output_type":"stream","text":"   id keyword location                                               text  \\\n0   1    None     None  Our Deeds are the Reason of this earthquake Ma...   \n1   4    None     None              Forest fire near La Ronge Sask Canada   \n2   5    None     None  All residents asked to shelter in place are be...   \n3   6    None     None  13000 people receive wildfires evacuation orde...   \n4   7    None     None  Just got sent this photo from Ruby Alaska as s...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  \n   id keyword location                                               text\n0   0    None     None                 Just happened a terrible car crash\n1   2    None     None  Heard about #earthquake is different cities, s...\n2   3    None     None  there is a forest fire at spot pond, geese are...\n3   9    None     None           Apocalypse lighting. #Spokane #wildfires\n4  11    None     None      Typhoon Soudelor kills 28 in China and Taiwan\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom nltk.corpus import stopwords\nimport re\n\ntrain_keyword = train_df[\"keyword\"].values\ntrain_location = train_df[\"location\"].values\ntrain_text = train_df[\"text\"].values\n\n#remove useless characters\nfor i in range(len(train_keyword)) :\n    train_keyword[i] = re.sub('[^0-9a-zA-Z ]', '', train_keyword[i])\n    train_location[i] = re.sub('[^0-9a-zA-Z ]', '', train_location[i])\n    train_text[i] = re.sub('[^0-9a-zA-Z ]', '', train_text[i])\n\n#make String data to numeric data\ntfidf_keyword = TfidfVectorizer(stop_words = stopwords.words('english'), ngram_range = (1, 2))\ntfidf_keyword.fit(train_keyword)\ntrain_keyword = tfidf_keyword.transform(train_keyword).toarray()\n\ntfidf_location = TfidfVectorizer(stop_words = stopwords.words('english'), ngram_range = (1, 2))\ntfidf_location.fit(train_location)\ntrain_location = tfidf_keyword.transform(train_location).toarray()\n\ntfidf_text = TfidfVectorizer(stop_words = stopwords.words('english'), ngram_range = (1, 2))\ntfidf_text.fit(train_text)\ntrain_text = tfidf_keyword.transform(train_text).toarray()\n\ntrain_x = []\ntrain_y = train_df[\"target\"].values\n\nfor i in range(len(train_y)) :\n    train_x.append([train_keyword[i], train_location[i], train_text[i]])\n    \ntrain_x = np.array(train_x, dtype=object)\nprint(train_x.shape) #7613, 3, 222\n#reshape for sklearn : sklearn allows 2D shape only\ntrain_x = train_x.reshape((train_x.shape[0], -1))\nprint(train_x.shape) #7613, 666","execution_count":49,"outputs":[{"output_type":"stream","text":"(7613, 3, 222)\n(7613, 666)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nimport warnings\nwarnings.filterwarnings('ignore')\n\nlg = LogisticRegression(random_state=0)\n\n#search the best parameter\nparams = { 'C': list(np.arange(1,10,0.1)) }\n\n#train\ngrid_cv = GridSearchCV(lg , param_grid=params , cv=5 ,scoring='accuracy', verbose=1 )\ngrid_cv.fit(train_x , train_y)\n\n#check best parameter and accuracy score\nprint(grid_cv.best_params_ , round(grid_cv.best_score_,4))","execution_count":50,"outputs":[{"output_type":"stream","text":"Fitting 5 folds for each of 90 candidates, totalling 450 fits\n{'C': 1.0} 0.5392\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_keyword = test_df[\"keyword\"].values\ntest_location = test_df[\"location\"].values\ntest_text = test_df[\"text\"].values\n\n#remove useless characters\nfor i in range(len(test_keyword)) :\n    test_keyword[i] = re.sub('[^0-9a-zA-Z ]', '', test_keyword[i])\n    test_location[i] = re.sub('[^0-9a-zA-Z ]', '', test_location[i])\n    test_text[i] = re.sub('[^0-9a-zA-Z ]', '', test_text[i])\n\n#make String data to numeric data\ntest_keyword = tfidf_keyword.transform(test_keyword).toarray()\n\ntest_location = tfidf_keyword.transform(test_location).toarray()\n\ntest_text = tfidf_keyword.transform(test_text).toarray()\n\ntest_x = []\n\nfor i in range(len(test_keyword)) :\n    test_x.append([test_keyword[i], test_location[i], test_text[i]])\n    \ntest_x = np.array(test_x, dtype=object)\nprint(test_x.shape) #3263, 3, 222\n#reshape for sklearn : sklearn allows 2D shape only\ntest_x = test_x.reshape((test_x.shape[0], -1))\nprint(test_x.shape) #3263, 666","execution_count":55,"outputs":[{"output_type":"stream","text":"(3263, 3, 222)\n(3263, 666)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = grid_cv.predict(test_x)\npred = pd.Series(pred, name = 'target')\ntarget_id = test_df[\"id\"]\nsave_data = pd.concat([target_id, pred], axis = 1)\nprint(save_data.head(5))\n\nsave_data.to_csv(\"result.csv\", index = False)","execution_count":58,"outputs":[{"output_type":"stream","text":"   id  target\n0   0       1\n1   2       1\n2   3       1\n3   9       0\n4  11       1\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}